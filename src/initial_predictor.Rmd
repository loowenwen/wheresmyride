---
title: "DSE3101 Project"
author: "Ryan Chow"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, include = TRUE,
                      fig.align = "center",  out.width = "80%")

rm(list = ls())

library(tidyverse)
library(lubridate)
library(readxl)
library(stringr)
library(rjson)
library(httr)
library(jsonlite)
library(geosphere)
library(sf)
library(purrr)
```


```{r}

# AUTHENTICATION


# define API endpoint for authentication
auth_url <- "https://www.onemap.gov.sg/api/auth/post/getToken"

# define email and password 
email <- "loowenwen1314@gmail.com"
password <- "sochex-6jobge-fomsYb"

# create JSON payload
auth_body <- list(
  email = email,
  password = password
)

# make API request
response <- POST(
  url = auth_url,
  body = auth_body,
  encode = "json"
)

# check response status
if (status_code(response) == 200) {
  # parse JSON response
  result <- content(response, as = "text", encoding = "UTF-8")
  data <- fromJSON(result)
  
  # extract token and store it as an environment variable
  token <- data$access_token
  Sys.setenv(ONEMAP_TOKEN = token)
  
} else {
  print(paste("Error:", status_code(response)))
}


```

### MRT Crowd Density by Station

```{r}
parse_crowd_json <- function(filepath) {
  raw <- fromJSON(filepath)
  stations_df <- raw$value$Stations[[1]]  # <-- the [1] is KEY

  all_intervals <- purrr::map2_dfr(
    stations_df$Station,
    stations_df$Interval,
    function(station_code, interval_df) {
      interval_df %>%
        mutate(
          Station = station_code,
          datetime = ymd_hms(Start, tz = "Asia/Singapore"),
          hour = hour(datetime),
          crowd_score = case_when(
            CrowdLevel == "l" ~ 1,
            CrowdLevel == "m" ~ 2,
            CrowdLevel == "h" ~ 3,
            TRUE ~ NA_real_
          ),
          time_slot = case_when(
            hour >= 6 & hour < 9 ~ "AM_peak",
            hour == 5 | (hour >= 9 & hour < 17) ~ "AM_offpeak",
            hour >= 17 & hour < 19 ~ "PM_peak",
            (hour >= 19 & hour <= 23) | (hour >= 0 & hour < 2) ~ "PM_offpeak",
            TRUE ~ "Other" # as the dataset is a 24hr forecast, it includes all timings. They will just be categorised as other since the MRT does not run from 1am - 4.59am. MRT generally starts at ~5.30am so timing from 5am onwards will be taken
          )
        )
    }
  )

  return(all_intervals)
}

# Now use the modified function to parse your MRT crowd data
mrt_crowdDensity <- bind_rows(
  parse_crowd_json("../data/MRT_CrowdDensity/CrowdDensity_CCL.json"),
  parse_crowd_json("../data/MRT_CrowdDensity/CrowdDensity_DTL.json"),
  parse_crowd_json("../data/MRT_CrowdDensity/CrowdDensity_EWL.json"),
  parse_crowd_json("../data/MRT_CrowdDensity/CrowdDensity_CEL.json"),
  parse_crowd_json("../data/MRT_CrowdDensity/CrowdDensity_CGL.json"),
  parse_crowd_json("../data/MRT_CrowdDensity/CrowdDensity_NEL.json"),
  parse_crowd_json("../data/MRT_CrowdDensity/CrowdDensity_NSL.json"),
  parse_crowd_json("../data/MRT_CrowdDensity/CrowdDensity_BPL.json"),
  parse_crowd_json("../data/MRT_CrowdDensity/CrowdDensity_SLRT.json"),
  parse_crowd_json("../data/MRT_CrowdDensity/CrowdDensity_PLRT.json"),
  parse_crowd_json("../data/MRT_CrowdDensity/CrowdDensity_TEL.json")
)

# Check the results
head(mrt_crowdDensity)

```


### Extracting Bus Services Function

```{r}
get_bus_routes <- function() {
  url <- "http://datamall2.mytransport.sg/ltaodataservice/BusRoutes"
  api_key <- "o6OuJxI3Re+qYgFQzb+4+w=="  # Replace with your own API key
  
  offset <- 0
  all_data <- list()
  
  repeat {
    response <- GET(url, add_headers(AccountKey = api_key), query = list("$skip" = offset))
    data <- content(response, "text", encoding = "UTF-8")
    parsed_data <- fromJSON(data, flatten = TRUE)
    
    if (length(parsed_data$value) == 0) break
    all_data <- append(all_data, list(parsed_data$value))
    offset <- offset + 500
  }
  
  bind_rows(all_data)
}

# Fetch all bus routes from API
bus_routes_raw <- get_bus_routes()

# Create lookup table: BusStopCode -> ServiceNo
bus_services_lookup <- bus_routes_raw %>%
  select(ServiceNo, BusStopCode) %>%
  distinct() %>%
  mutate(BusStopCode = str_pad(as.character(BusStopCode), 5, side = "left", pad = "0"))
```

### Engineering of all Features

```{r}
engineer_features <- function(lat, lon) {

    # Load datasets
  
  mrt_lrt_coords <- read_csv("../data/MRTStations.csv", show_col_types = FALSE)
  
  #mrt_passVol <- read_csv("../data/transport_node_train_202502.csv", show_col_types = FALSE) 
  #NO LONGER USED, CROWD DENSITY USED INSTEAD

  #Time based Bus passernger volume
  busstops_passengerVolume <- read_csv("../data/PV_busstops.csv", show_col_types = FALSE) %>%
    filter(DAY_TYPE == "WEEKDAY") %>%
    mutate(
      PT_CODE = str_pad(as.character(PT_CODE), 5, "left", "0"),
      BusStop_code = PT_CODE,
      time_slot = case_when(
        TIME_PER_HOUR >= 6 & TIME_PER_HOUR < 9 ~ "AM_peak",
        TIME_PER_HOUR == 5 | (TIME_PER_HOUR >= 9 & TIME_PER_HOUR < 17) ~ "AM_offpeak",
        TIME_PER_HOUR >= 17 & TIME_PER_HOUR < 19 ~ "PM_peak",
        (TIME_PER_HOUR >= 19 & TIME_PER_HOUR <= 23) | (TIME_PER_HOUR >= 0 & TIME_PER_HOUR < 2) ~ "PM_offpeak",
        TRUE ~ "Other"
      )
    ) %>%
    group_by(BusStop_code, time_slot) %>%
    summarise(
      daily_avg_vol = sum(TOTAL_TAP_IN_VOLUME, na.rm = TRUE) / 20,
      .groups = 'drop'
    )
  
  # Finding coordinates of al bus stops
  bus_coords <- st_read("../data/BusStopLocation_Nov2024/BusStop.shp", quiet = TRUE) %>%
    rename(BusStop_code = BUS_STOP_N) %>%
    st_transform(crs = 4326) %>%
    mutate(
      BusStop_code = str_pad(as.character(BusStop_code), 5, "left", "0"),
      Longitude = st_coordinates(geometry)[,1],
      Latitude = st_coordinates(geometry)[,2]
    ) %>%
    st_drop_geometry()

  ### MRT ANALYSIS
  mrt_coords <- mrt_lrt_coords %>%
    mutate(dist = distHaversine(cbind(Longitude, Latitude), c(lon, lat))) %>%
    filter(dist < 500)

  num_mrt_stations <- nrow(mrt_coords)
  avg_dist_mrt <- ifelse(num_mrt_stations > 0, mean(mrt_coords$dist), NA)
  
  if (num_mrt_stations == 0) {
    message("No MRT stations found within 500m radius. MRT score may be low or NA.")
            }

  mrt_station_names <- mrt_coords$STN_NAME

  # Extract MRT line codes (e.g., NS1 -> NS)
  mrt_lines <- mrt_coords$STN_NO %>%
    str_split("/") %>%
    unlist() %>%
    str_extract("^[A-Z]+") %>%
    unique()

  num_unique_mrt_lines <- length(mrt_lines)

  ### BUS ANALYSIS
  bus_nearby <- bus_coords %>%
    mutate(dist = distHaversine(cbind(Longitude, Latitude), c(lon, lat))) %>%
    filter(dist < 500)

  num_bus_stops <- nrow(bus_nearby)
  avg_dist_bus <- ifelse(num_bus_stops > 0, mean(bus_nearby$dist), NA)
  
  if (num_bus_stops == 0) {
    message("No bus stops found within 500m radius. Bus score may be low or NA.")
    }

  nearby_bus_codes <- bus_nearby$BusStop_code

  # Join to busRoutes lookup to get services at nearby stops
  bus_services_list <- bus_services_lookup %>%
    filter(BusStopCode %in% nearby_bus_codes) %>%
    pull(ServiceNo) %>%
    unique()

  num_unique_bus_services <- length(bus_services_list)

  ### CROWD / VOLUME ANALYSIS
  mrtNames_crowdDensity <- mrt_crowdDensity %>%
    rowwise() %>%
    mutate(STN_NAME = mrt_lrt_coords$STN_NAME[
      which(str_detect(mrt_lrt_coords$STN_NO, Station))[1]
    ])

  mrt_crowd_scores <- mrtNames_crowdDensity %>%
    filter(STN_NAME %in% mrt_station_names) %>%
    group_by(time_slot) %>%
    summarise(
      avg_crowd = mean(crowd_score, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    pivot_wider(names_from = time_slot, values_from = avg_crowd, names_prefix = "mrt_")


  bus_volume_by_slot <- bus_nearby %>%
    left_join(busstops_passengerVolume, by = "BusStop_code") %>%
    group_by(time_slot) %>%
    summarise(avg_vol = mean(daily_avg_vol, na.rm = TRUE), .groups = "drop") %>%
    pivot_wider(names_from = time_slot, values_from = avg_vol, names_prefix = "bus_")

  ### RETURN
  return(list(
    # Quantitative features
    num_mrt_stations = num_mrt_stations,
    avg_dist_mrt = avg_dist_mrt,
    num_unique_mrt_lines = num_unique_mrt_lines,
    num_bus_stops = num_bus_stops,
    avg_dist_bus = avg_dist_bus,
    num_unique_bus_services = num_unique_bus_services,
    mrt_crowd_AM_peak = mrt_crowd_scores$mrt_AM_peak,
    mrt_crowd_AM_offpeak = mrt_crowd_scores$mrt_AM_offpeak,
    mrt_crowd_PM_peak = mrt_crowd_scores$mrt_PM_peak,
    mrt_crowd_PM_offpeak = mrt_crowd_scores$mrt_PM_offpeak,
    bus_volume_AM_peak = bus_volume_by_slot$bus_AM_peak,
    bus_volume_AM_offpeak = bus_volume_by_slot$bus_AM_offpeak,
    bus_volume_PM_peak = bus_volume_by_slot$bus_PM_peak,
    bus_volume_PM_offpeak = bus_volume_by_slot$bus_PM_offpeak,

    # Detailed lists
    nearby_mrt_stations = mrt_station_names,
    nearby_mrt_lines = mrt_lines,
    nearby_bus_stops = nearby_bus_codes,
    bus_services_available = bus_services_list
  ))
}

```

### Predict score using current features, equally weighted

```{r}

normalised_score <- function(features) {
  # ---- Normalize/scale scores ----
  score_mrt <- mean(c(
    ifelse(is.na(features$num_mrt_stations), 0, features$num_mrt_stations / 3),
    ifelse(is.na(features$avg_dist_mrt), 0, 1 / (features$avg_dist_mrt + 1)),
    ifelse(is.na(features$num_unique_mrt_lines), 0, features$num_unique_mrt_lines / 3)
    ))  * 100
                    

  score_bus <- mean(c(
    ifelse(is.na(features$num_bus_stops), 0, features$num_bus_stops / 20),
    ifelse(is.na(features$avg_dist_bus), 0, 1 / (features$avg_dist_bus + 1)),
    ifelse(is.na(features$num_unique_bus_services), 0, features$num_unique_bus_services / 30)
    ))  * 100


  # Normalise distances to [0,1], where closer = better walkability  
  norm_mrt_dist <- max(0, 1 - (ifelse(is.na(features$avg_dist_mrt), 500, features$avg_dist_mrt) / 500))
  norm_bus_dist <- max(0, 1 - (ifelse(is.na(features$avg_dist_bus), 500, features$avg_dist_bus) / 500))
  
  # Compute final walkability score out of 100
  walkability_score <- mean(c(norm_mrt_dist, norm_bus_dist)) * 100

  # Compute congestion as its own score
  calc_penalty <- function(mrt_crowd, bus_volume) {
    mean(c(
      ifelse(is.na(mrt_crowd), 0, (mrt_crowd - 1) / 2),
      ifelse(is.na(bus_volume), 0, bus_volume / 500)
    )) * 10
  }
  
  congestion_AM_peak <- calc_penalty(features$mrt_crowd_AM_peak, features$bus_volume_AM_peak)
  congestion_AM_offpeak <- calc_penalty(features$mrt_crowd_AM_offpeak, features$bus_volume_AM_offpeak)
  congestion_PM_peak <- calc_penalty(features$mrt_crowd_PM_peak, features$bus_volume_PM_peak)
  congestion_PM_offpeak <- calc_penalty(features$mrt_crowd_PM_offpeak, features$bus_volume_PM_offpeak)
  
  congestion_penalty <- mean(c(
    congestion_AM_peak,
    congestion_AM_offpeak,
    congestion_PM_peak,
    congestion_PM_offpeak
  ), na.rm = TRUE)
  
  final_score <- (mean(c(score_mrt, score_bus, walkability_score)) - congestion_penalty)


  # ---- Create breakdown ----
  breakdown <- list(
    total_score = final_score,

    score_mrt = score_mrt,
    score_bus = score_bus,
    walkability_score = walkability_score,
    congestion_penalty = congestion_penalty,

    mrt_score_components = list(
      num_mrt_stations = features$num_mrt_stations,
      avg_dist_mrt = features$avg_dist_mrt,
      num_unique_mrt_lines = features$num_unique_mrt_lines,
      nearby_mrt_stations = features$nearby_mrt_stations,
      nearby_mrt_lines = features$nearby_mrt_lines
    ),

    bus_score_components = list(
      num_bus_stops = features$num_bus_stops,
      avg_dist_bus = features$avg_dist_bus,
      num_unique_bus_services = features$num_unique_bus_services,
      nearby_bus_stops = features$nearby_bus_stops,
      bus_services_available = features$bus_services_available
    ),

    congestion_components = list(
      bus_volume_AM_peak = features$bus_volume_AM_peak,
      bus_volume_AM_offpeak = features$bus_volume_AM_offpeak,
      bus_volume_PM_peak = features$bus_volume_PM_peak,
      bus_volume_PM_offpeak = features$bus_volume_PM_offpeak,
      
      mrt_crowd_AM_peak = features$mrt_crowd_AM_peak,
      mrt_crowd_AM_offpeak = features$mrt_crowd_AM_offpeak,
      mrt_crowd_PM_peak = features$mrt_crowd_PM_peak,
      mrt_crowd_PM_offpeak = features$mrt_crowd_PM_offpeak
    ),
    
    time_slot_congestion = list(
      AM_peak = congestion_AM_peak,
      AM_offpeak = congestion_AM_offpeak,
      PM_peak = congestion_PM_peak,
      PM_offpeak = congestion_PM_offpeak
    ),

      walkability = list(
        avg_mrt_distance = features$avg_dist_mrt,
        avg_bus_distance = features$avg_dist_bus,
        walkability_score = walkability_score
        )
  )

  return(breakdown)
}

```


```{r}
predict_accessibility <- function(postal_code) {
  base_url <- "https://www.onemap.gov.sg/api/common/elastic/search"
  token <- Sys.getenv("ONEMAP_TOKEN")
  
  request_url <- paste0(base_url, "?searchVal=", postal_code, "&returnGeom=Y&getAddrDetails=Y")
  
  res <- GET(request_url, add_headers(Authorization = token))
  parsed <- content(res, as = "parsed", type = "application/json")
  
  if (length(parsed$results) == 0) {
    stop("No results found for this postal code.")
  }
  
  lat <- as.numeric(parsed$results[[1]]$LATITUDE)
  lon <- as.numeric(parsed$results[[1]]$LONGITUDE)
  
  features <- engineer_features(lat, lon)

  score_breakdown <- normalised_score(features)
  
  return(list(
    postal_code = postal_code,
    latitude = lat,
    longitude = lon,
    score = score_breakdown$total_score,
    score_breakdown = score_breakdown,
    features = features
  ))
}
```


```{r}
# Test
result <- predict_accessibility("543305")
print(result$score_breakdown)
```



